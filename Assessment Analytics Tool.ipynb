{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bddb7235",
   "metadata": {},
   "source": [
    "# Designing a Database Schema for Assessment Analytics Tool(AAT) Project\n",
    "\n",
    "The notebook below contains a lot of my though process and experimenting for this \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "* [Version 3.0](#version3)\n",
    "    * [Imports & Exports](#v3_1)\n",
    "        * [Imports](#v3_1_1)\n",
    "        * [Exports](#v3_1_2)\n",
    "    * [Creating Fake Data](#v3_2)\n",
    "        * [Roles Class](#v3_2_1)\n",
    "        * [Staff & Students](#v3_2_2)\n",
    "        * [Classrooms](#v3_2_3)\n",
    "    * [Testing Data](#v3_3)\n",
    "* [Version 2.0](#version2)\n",
    "    * [Imports & Exports](#v2_1)\n",
    "        * [Imports](#v2_1_1)\n",
    "        * [Exports](#v2_1_2)\n",
    "    * [Creating Fake Data](#v2_2)\n",
    "        * [Years, Schools & Grades](#v2_2_1)\n",
    "        * [Staff](#v2_2_2)\n",
    "        * [Students](#v2_2_3)\n",
    "    * [Assessment Info](#v2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521bedd5",
   "metadata": {},
   "source": [
    "# Version 3.0 <a class=\"anchor\" id=\"version3\"></a>\n",
    " \n",
    "<strong>Creating an MVP: Refocusing on a smaller data set and basic functionality.</strong>\n",
    "<i><p>Data needed:\n",
    "<ul><li>List of students (name, grade)</li>\n",
    "<li>Users/teachers</li>\n",
    "<li>Info for one Assessment (standards, etc.)</li>\n",
    "<li>Student scores</li>\n",
    "</ul>\n",
    "</p></i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8dc9c1",
   "metadata": {},
   "source": [
    "## Imports & Exports <a id=\"v3_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ecd9a",
   "metadata": {},
   "source": [
    "### Imports<a id=\"v3_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5bb3e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from faker import Faker\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb50d20",
   "metadata": {},
   "source": [
    "### Exports<a id=\"v3_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b61629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#staff names,email and id numbers\n",
    "staff = staff_df.to_csv('staff.csv')\n",
    "\n",
    "#classroom info: school, school year, grade_level, teacher (later-cohort/student group #?)\n",
    "classrooms = staff_classes_df.to_csv('classrooms.csv')\n",
    "\n",
    "#student names, email and id numbers\n",
    "students = students_df.to_csv('students.csv')\n",
    "\n",
    "#association table: classroom_id, student_id (group# id?)\n",
    "student_classes = student_classes_df.to_csv('student_classes.csv')\n",
    "\n",
    "#assessment name, assessment component name, subject, norms (based on grade_level and period)\n",
    "assessment_standards = assessment_standards_df.to_csv('assessment_standards.csv')\n",
    "\n",
    "# #student_class_id, assessment component, score\n",
    "# assessment_scores = assessment_scores_df.to_csv('assessment_scores.csv')\n",
    "\n",
    "staff\n",
    "classrooms\n",
    "students\n",
    "student_classes\n",
    "assessment_standards\n",
    "assessment_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a23ed",
   "metadata": {},
   "source": [
    "## Creating Fake Data <a id=\"v3_2\"></a>\n",
    "### Roles Class <a id=\"v3_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50e2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Permission: #Permission Constants - BITWISE\n",
    "    '''Varying permission levels to be assigned individually or to Roles'''\n",
    "    PUBLIC = 1    # 0b00001\n",
    "    STUDENT = 2   # 0b00010\n",
    "    CLASS = 4     # 0b00100\n",
    "    GRADE = 8     # 0b01000\n",
    "    SCHOOL = 16   # 0b10000\n",
    "    DISTRICT = 32 # 0b100000\n",
    "    YOY = 64      # 0b1000000\n",
    "    \n",
    "    def insert_roles():\n",
    "        roles = {\n",
    "            'Public':[Permission.PUBLIC],\n",
    "            'Student':[Permission.STUDENT],\n",
    "            'Teacher':[Permission.STUDENT, Permission.CLASS],\n",
    "            'Principal':[Permission.STUDENT, Permission.CLASS, Permission.GRADE, Permission.YOY],\n",
    "            'Admin':[Permission.STUDENT, Permission.CLASS, Permission.GRADE, Permission.DISTRICT, Permission.YOY]\n",
    "        }\n",
    "        \n",
    "        for r in roles:\n",
    "            roles = role_name\n",
    "\n",
    "\n",
    "Permission.insert_roles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22764894",
   "metadata": {},
   "source": [
    "### Staff & Students <a id=\"v3_2_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16531e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_emails(person_name):\n",
    "    '''Create email using first initial & last name of person's full name'''\n",
    "    p= person_name.split(\" \")\n",
    "    first_initial = p[0][0]\n",
    "    last_name = p[1]\n",
    "    email = (f'{first_initial}{last_name}@simpleschooldistrict.org').lower()\n",
    "    return email\n",
    "\n",
    "def make_people(num,role):\n",
    "    '''Generate fake student or staff data'''\n",
    "    fake_names = [] #list of fake student names\n",
    "    for i in range(num):\n",
    "        name = f'{fake.first_name()} {fake.last_name()}'\n",
    "        fake_names.append(name)\n",
    "    if role == 0:\n",
    "        fake_people = [{'id': np.random.choice(np.arange(10000,20000),replace=False),\n",
    "            'name':(fake_names[x]),\n",
    "            'email': make_emails(fake_names[x]),\n",
    "            'role': role}for x in range(num)]\n",
    "    else:\n",
    "        fake_people = [{'id': np.random.choice(np.arange(1100,2000),replace=False),\n",
    "            'name':(fake_names[x]),\n",
    "            'email': make_emails(fake_names[x]),\n",
    "            'role': role}for x in range(num)]\n",
    "    return fake_people\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027e58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_id': '21-SPA-0',\n",
       "  'school_year': 2021,\n",
       "  'school_name': 'Simple Pimple Academy',\n",
       "  'grade_level': 0,\n",
       "  'teacher_id': 1557},\n",
       " {'class_id': '21-SPA-1',\n",
       "  'school_year': 2021,\n",
       "  'school_name': 'Simple Pimple Academy',\n",
       "  'grade_level': 1,\n",
       "  'teacher_id': 1194},\n",
       " {'class_id': '21-SPA-2',\n",
       "  'school_year': 2021,\n",
       "  'school_name': 'Simple Pimple Academy',\n",
       "  'grade_level': 2,\n",
       "  'teacher_id': 1663},\n",
       " {'class_id': '21-SPA-3',\n",
       "  'school_year': 2021,\n",
       "  'school_name': 'Simple Pimple Academy',\n",
       "  'grade_level': 3,\n",
       "  'teacher_id': 1574},\n",
       " {'class_id': '21-SPA-4',\n",
       "  'school_year': 2021,\n",
       "  'school_name': 'Simple Pimple Academy',\n",
       "  'grade_level': 4,\n",
       "  'teacher_id': 1500},\n",
       " {'class_id': '21-SPA-5',\n",
       "  'school_year': 2021,\n",
       "  'school_name': 'Simple Pimple Academy',\n",
       "  'grade_level': 5,\n",
       "  'teacher_id': 1139}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creating classes pk-5 for 2021 school year\n",
    "x = 0\n",
    "student_classes = []\n",
    "staff_classes = []\n",
    "student_info = []\n",
    "while x <= 5:\n",
    "    for s in staff:\n",
    "        #make a roster of students..r_1 = make_people(np.random.randint(8,15),0)\n",
    "        student_info.append(r_1)\n",
    "        \n",
    "    \n",
    "        #create a classroom x=grade_level\n",
    "        staff_class = make_fake_class(2021, 'Simple Pimple Academy', x, s['id'])\n",
    "\n",
    "        #add list of classes to staff dict (this might be screwing me up)\n",
    "#         s['classes'] = [staff_class['class_id']]\n",
    "        \n",
    "        #unique ID for student/class combo\n",
    "        student_classes.append([{\n",
    "            'id': (f\"{r['id']}-{x}\"),\n",
    "            'student_id': r['id'],\n",
    "            'class_id': staff_class['class_id']\n",
    "        }for r in r_1])\n",
    "        \n",
    "        staff_classes.append(staff_class)\n",
    "        x += 1\n",
    "\n",
    "## later I would have some functionality to bump students up a grade       \n",
    "\n",
    "student_classes\n",
    "staff_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c80e5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#making a small staff\n",
    "staff = make_people(5, 1)\n",
    "\n",
    "#adding myself as a staff member!\n",
    "staff.append({'id': 1139,\n",
    "        'name':'Liz Francese',\n",
    "        'email':make_emails('Liz Francese'),\n",
    "        'role':1\n",
    "    })\n",
    "\n",
    "staff_df = pd.DataFrame(staff)\n",
    "staff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575937f4",
   "metadata": {},
   "source": [
    "### Classrooms<a id=\"v3_2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e039b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fake_class(roster, year, school, grade_level, teacher_id):\n",
    "    '''Provide data needed to make a classroom'''\n",
    "    #is this an appropriate place for **kwargs? too specific?\n",
    "    year_id = year-2000\n",
    "    school_id = (f\"{school.split(' ')[0][0]}{school.split(' ')[1][0]}{school.split(' ')[2][0]}\") #taking initials-could probably just use regex\n",
    "    my_class = {\n",
    "        'class_id':(f'{year_id}-{school_id}-{grade_level}'),\n",
    "        'school_year': year,\n",
    "        'school_name': school,\n",
    "        'grade_level': grade_level,\n",
    "        'teacher_id': teacher_id,\n",
    "#         'student_id': [sub['id'] for sub in roster]\n",
    "    }\n",
    "    return my_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b3f55726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_class_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>classroom_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14399-0</td>\n",
       "      <td>14399</td>\n",
       "      <td>21-SPA-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19389-0</td>\n",
       "      <td>19389</td>\n",
       "      <td>21-SPA-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12758-0</td>\n",
       "      <td>12758</td>\n",
       "      <td>21-SPA-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18585-0</td>\n",
       "      <td>18585</td>\n",
       "      <td>21-SPA-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13161-0</td>\n",
       "      <td>13161</td>\n",
       "      <td>21-SPA-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>19270-5</td>\n",
       "      <td>19270</td>\n",
       "      <td>21-SPA-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>15481-5</td>\n",
       "      <td>15481</td>\n",
       "      <td>21-SPA-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>10785-5</td>\n",
       "      <td>10785</td>\n",
       "      <td>21-SPA-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>11093-5</td>\n",
       "      <td>11093</td>\n",
       "      <td>21-SPA-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>19695-5</td>\n",
       "      <td>19695</td>\n",
       "      <td>21-SPA-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_class_id  student_id classroom_id\n",
       "0           14399-0       14399     21-SPA-0\n",
       "1           19389-0       19389     21-SPA-0\n",
       "2           12758-0       12758     21-SPA-0\n",
       "3           18585-0       18585     21-SPA-0\n",
       "4           13161-0       13161     21-SPA-0\n",
       "..              ...         ...          ...\n",
       "62          19270-5       19270     21-SPA-5\n",
       "63          15481-5       15481     21-SPA-5\n",
       "64          10785-5       10785     21-SPA-5\n",
       "65          11093-5       11093     21-SPA-5\n",
       "66          19695-5       19695     21-SPA-5\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows=[]\n",
    "for student_class in student_classes:\n",
    "    for sc in student_class:\n",
    "        student_class_id = sc['id']\n",
    "        student_id = sc['student_id']\n",
    "        classroom_id = sc['class_id']\n",
    "        rows.append([student_class_id,student_id,classroom_id])\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "student_classes_df = df.rename(columns={0:'student_class_id', 1:'student_id',2:'classroom_id'})\n",
    "\n",
    "student_classes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8964b949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>school_year</th>\n",
       "      <th>school_name</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>teacher_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21-SPA-0</td>\n",
       "      <td>2021</td>\n",
       "      <td>Simple Pimple Academy</td>\n",
       "      <td>0</td>\n",
       "      <td>1911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21-SPA-1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Simple Pimple Academy</td>\n",
       "      <td>1</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21-SPA-2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Simple Pimple Academy</td>\n",
       "      <td>2</td>\n",
       "      <td>1857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21-SPA-3</td>\n",
       "      <td>2021</td>\n",
       "      <td>Simple Pimple Academy</td>\n",
       "      <td>3</td>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21-SPA-4</td>\n",
       "      <td>2021</td>\n",
       "      <td>Simple Pimple Academy</td>\n",
       "      <td>4</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21-SPA-5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Simple Pimple Academy</td>\n",
       "      <td>5</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_id  school_year            school_name  grade_level  teacher_id\n",
       "0  21-SPA-0         2021  Simple Pimple Academy            0        1911\n",
       "1  21-SPA-1         2021  Simple Pimple Academy            1        1662\n",
       "2  21-SPA-2         2021  Simple Pimple Academy            2        1857\n",
       "3  21-SPA-3         2021  Simple Pimple Academy            3        1609\n",
       "4  21-SPA-4         2021  Simple Pimple Academy            4        1293\n",
       "5  21-SPA-5         2021  Simple Pimple Academy            5        1139"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forgot to make the students table :D\n",
    "rows=[]\n",
    "for data in student_info:\n",
    "    for d in data:\n",
    "        data_row = d['id']\n",
    "        name = d['name']\n",
    "        email = d['email']\n",
    "        role = d['role']\n",
    "        rows.append([data_row, name, email, role])\n",
    "\n",
    "students_df = pd.DataFrame(rows)\n",
    "students_df = students_df.rename(columns={0:'student_id',1:'student_name',2:'student_email',3:'role'}\n",
    ")\n",
    "students_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32166c33",
   "metadata": {},
   "source": [
    "## Testing Data<a id=\"v3_3\"></a>\n",
    "<p>Vermont and several other US states are moving towards model in K-12 education called Multi-Tiered Systems of Support or MTSS. The model is designed with the goal of more accurately and efficiently addressing student need. Need is determined by comiling state and other assessments for literacy and math (and sometimes social emotional assessments) and placing the student scores into one of three 'tiers'. Tiers represent the 1-10th, 11-50th & 51-99th percentile of scores, either on a nationally normed scale or normed locally, within the classroom. Supports for students are then targeted based on subject matter and dosed based on tier. Diagnostics provide more specific insight for educational supports and aid in more fluid support dosing. The approach is seen as more equitable and less stigmatizing than historical approaches and is designed to help teachers meet more student needs within the core classroom setting.</p>\n",
    "<p>Originally I had included state assessment data in here, which uses national norms that change based on the grade level and period (fall, winter, spring). To get our MVP rolling, however, I'm instead using just two diagnostics-one literacy and one math- that are required for all students to take in the XXXX school district.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ac306018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>component_id</th>\n",
       "      <th>component_name</th>\n",
       "      <th>assessment_name</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>period</th>\n",
       "      <th>rank_name</th>\n",
       "      <th>rank_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>literacy</td>\n",
       "      <td>PARLW</td>\n",
       "      <td>Letter Word Calling</td>\n",
       "      <td>Predictive Assessment of Reading</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>literacy</td>\n",
       "      <td>PARLW</td>\n",
       "      <td>Letter Word Calling</td>\n",
       "      <td>Predictive Assessment of Reading</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>literacy</td>\n",
       "      <td>PARLW</td>\n",
       "      <td>Letter Word Calling</td>\n",
       "      <td>Predictive Assessment of Reading</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>literacy</td>\n",
       "      <td>PARLW</td>\n",
       "      <td>Letter Word Calling</td>\n",
       "      <td>Predictive Assessment of Reading</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>literacy</td>\n",
       "      <td>PARLW</td>\n",
       "      <td>Letter Word Calling</td>\n",
       "      <td>Predictive Assessment of Reading</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject component_id       component_name  \\\n",
       "0  literacy        PARLW  Letter Word Calling   \n",
       "1  literacy        PARLW  Letter Word Calling   \n",
       "2  literacy        PARLW  Letter Word Calling   \n",
       "3  literacy        PARLW  Letter Word Calling   \n",
       "4  literacy        PARLW  Letter Word Calling   \n",
       "\n",
       "                    assessment_name  grade_level  period rank_name  rank_score  \n",
       "0  Predictive Assessment of Reading            0       1    Tier I          80  \n",
       "1  Predictive Assessment of Reading            0       3    Tier I          80  \n",
       "2  Predictive Assessment of Reading            0       2    Tier I          80  \n",
       "3  Predictive Assessment of Reading            1       1    Tier I          80  \n",
       "4  Predictive Assessment of Reading            1       3    Tier I          80  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing assessments and diagnostics data\n",
    "assessment_standards_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "#cleaning data\n",
    "assessment_standards_df = assessment_standards_df.drop(columns=['Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9'])\n",
    "\n",
    "subjects = {'Predictive Assessment of Reading':'literacy', 'Primary Number & Operations Assessment':'math'}\n",
    "\n",
    "assessment_standards_df['subject'] = assessment_standards_df['assessment_name'].map(subjects)\n",
    "assessment_standards_df = assessment_standards_df.iloc[:,[7,2,4,3,6,5,0,1]]\n",
    "\n",
    "#dropping the tiers from data set <<< If I decide to norm locally, as a calculation on the student score table\n",
    "assessment_df = assessment_standards_df.iloc[:,[7,2,1,3]]\n",
    "assessment_df = assessment_df.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=True)\n",
    "\n",
    "#without norms\n",
    "assessment_df.head()\n",
    "\n",
    "\n",
    "#with norms (could of course be another table with just component ID)\n",
    "assessment_standards_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2c4ffccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PARLW', 'PARPA', 'PARPN', 'PARRN', 'PARTSS', 'PNOABS', 'PNOAEM',\n",
       "       'PNOAEQ', 'PNOAFS', 'PNOAGPV', 'PNOAOP', 'PNOASN'], dtype=object)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pd.Series(assessment_standards_df.component_id).unique()\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "24597ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake PAR (Predictive Assessment of Reading) data\n",
    "\n",
    "#PAR is 80-130 across the board\n",
    "\n",
    "par_rng = np.random.default_rng()\n",
    "par_rng.choice(175,15) \n",
    "\n",
    "# student_class_id  |   period  |   component_id    |   student_score \n",
    "\n",
    "\n",
    "#PAR Component List\n",
    "par_components = ['PARLW', 'PARPA', 'PARPN', 'PARRN', 'PARTSS']\n",
    "pnoa_components = {'PNOAEM':20, 'PNOAFS':20, 'PNOAGPV':80, 'PNOAOP':20, 'PNOASN':40}\n",
    "\n",
    "#make data for one season (rest will be in Flask)\n",
    "score_data={}\n",
    "x=0\n",
    "\n",
    "#get student_classes_id\n",
    "student_class_ids = pd.Series(student_classes_df['student_class_id'])\n",
    "\n",
    "\n",
    "for class_id in student_class_ids:\n",
    "    for item in assessment_standards_df:\n",
    "        if item[4] == class_id[0][-1]:\n",
    "                print ('Match\\n' + item[4])\n",
    "\n",
    "\n",
    "# score_df = pd.DataFrame(score_data)\n",
    "# score_df\n",
    "# assessment_scores_df = score_df.transpose()\n",
    "# assessment_scores_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73647b90",
   "metadata": {},
   "source": [
    "# Version 2.0 <a id=\"v3\"></a>\n",
    "\n",
    "<p>After quitting my job, I decided to make fake data, rather than import, clean and work with ths (massive, confusing, inconsistent) data I had from the school district. I was still, however, modelling the data after our school district structure and wasn't quite grasping the idea of incremental development. I still had it in my mind, especially in regards to the database, that I had to have every element laid out perfectly and that adding data points or complexity later would be \"going backwards\".</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b18b1",
   "metadata": {},
   "source": [
    "## Imports & Exports <a id=\"v2_1\"></a>\n",
    "### Imports <a id=\"v2_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39edae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (219037983.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install Faker\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install Faker\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a575ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "from faker import Faker\n",
    "fake = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38d194",
   "metadata": {},
   "source": [
    "### Exports <a id=\"v2_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5712c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original database had 17 tables\n",
    "\n",
    "# classrooms_df = class_teacher_names.to_csv('classrooms.csv')\n",
    "# rosters_df = all_rosters_df.to_csv('rosters.csv')\n",
    "# staff_df = staff_df.to_csv('staff.csv')\n",
    "# students_df = students_df.to_csv('students.csv')\n",
    "# assements_df = assessments_df.to_csv('assessments.csv') #lol spelling error\n",
    "# scores_df = scores_df.to_csv('scores.csv')\n",
    "\n",
    "\n",
    "#other tables:\n",
    "#users\n",
    "#roles & permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8918c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (class_teacher_names.columns)\n",
    "print (all_rosters_df.columns)\n",
    "print (staff_df.columns)\n",
    "print (students_df.columns)\n",
    "print (assessments_df.columns)\n",
    "print (scores_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7faa36",
   "metadata": {},
   "source": [
    "## Creating Fake Data <a id=\"v2_2\"></a>\n",
    "### Years, Schools & Grades <a id=\"v2_2_1\"></a>\n",
    "Original data set held years, schools and grades in different tables. Creating a new fake data set to hold all info in one table, making it (hopefully) easier to bring into Flask and manipulate.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2636acc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2021, 'Brown Bear Middle School', 0, 11),\n",
       " (2021, 'Cherry Tree Elementary School', 0, 10),\n",
       " (2021, 'Mulberry Elementary School', 0, 9),\n",
       " (2021, 'Sunny Elementary School', 0, 8),\n",
       " (2021, 'Dunns Corners Elementary School', 0, 7),\n",
       " (2021, 'State Street Elementary School', 0, 6),\n",
       " (2021, 'Bene Gesserit School', 0, 5),\n",
       " (2021, 'Brown Bear Middle School', 1, 4),\n",
       " (2021, 'Cherry Tree Elementary School', 1, 3),\n",
       " (2021, 'Mulberry Elementary School', 1, 2),\n",
       " (2021, 'Sunny Elementary School', 1, 1),\n",
       " (2021, 'Dunns Corners Elementary School', 1, 0)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6 elementary schools, one middle school\n",
    "school_names = ['Brown Bear Middle School','Cherry Tree Elementary School','Mulberry Elementary School','Sunny Elementary School','Dunns Corners Elementary School',\n",
    "                'State Street Elementary School','Bene Gesserit School']\n",
    "\n",
    "#years of data\n",
    "years = [2021,2022,2023,2024]\n",
    "#grades Pre-k-8\n",
    "grades = [i for i in range (9)]\n",
    "\n",
    "cohorts = [i for i in range (12)]\n",
    "\n",
    "#new lists to form tuples\n",
    "years_2 = []\n",
    "schools_2 = []\n",
    "grades_2 = []\n",
    "cohorts_2 = []\n",
    "\n",
    "#create entry for each year/school/grade level\n",
    "for year in years:\n",
    "    for grade in grades:\n",
    "        if cohorts:\n",
    "            cohorts_2.append(cohorts.pop())\n",
    "        for school in school_names:\n",
    "            years_2.append(year)\n",
    "            schools_2.append(school)\n",
    "            grades_2.append(grade)\n",
    "\n",
    "tuples = list(zip(years_2,schools_2,grades_2,cohorts_2))\n",
    "            \n",
    "def create_class_ids(school_tuples):\n",
    "    '''create unique identifier for classrooms'''\n",
    "    class_ids = []\n",
    "    for x in school_tuples:\n",
    "        yr_id = x[0]-2000\n",
    "        grade_id=x[-1]\n",
    "        school_id=x[1][:3]\n",
    "        class_ids.append(f'{yr_id}-{grade_id}-{school_id}')\n",
    "    return class_ids\n",
    "\n",
    "class_ids = create_class_ids(tuples)\n",
    "tuple_with_id = list(zip(years_2,schools_2,grades_2, class_ids))\n",
    "school_classes = pd.DataFrame(tuple_with_id)\n",
    "school_data = school_classes.rename(columns={0:'school_year', 1:'school_name',2:'grade_level',3:'class_id'})\n",
    "school_data\n",
    "\n",
    "school_update = school_data.drop(school_data[(school_data['school_name']=='Brown Bear Middle School') & (\n",
    "    school_data['grade_level']<=5)].index)\n",
    "\n",
    "school_update_2 = school_update.drop(school_update[(school_update['school_name']!='Brown Bear Middle School') & (\n",
    "    school_update['grade_level']>=6)].index) \n",
    "school_update_2.head()\n",
    "school_update_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc6e728",
   "metadata": {},
   "source": [
    "### Staff <a id=\"v2_2_1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d4d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #in case of too many iterations\n",
    "fake.unique.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc4f73e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>staff_id</th>\n",
       "      <th>staff_first</th>\n",
       "      <th>staff_last</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>school_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Cathy</td>\n",
       "      <td>Dominguez</td>\n",
       "      <td>4</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>Holt</td>\n",
       "      <td>4</td>\n",
       "      <td>Sunny Elementary School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>Marc</td>\n",
       "      <td>Mcintosh</td>\n",
       "      <td>4</td>\n",
       "      <td>Cherry Tree Elementary School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Ricky</td>\n",
       "      <td>Mcgee</td>\n",
       "      <td>2</td>\n",
       "      <td>Mulberry Elementary School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>Gavin</td>\n",
       "      <td>Holloway</td>\n",
       "      <td>1</td>\n",
       "      <td>Cherry Tree Elementary School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1065</td>\n",
       "      <td>Sheena</td>\n",
       "      <td>Clayton</td>\n",
       "      <td>8</td>\n",
       "      <td>Mulberry Elementary School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1066</td>\n",
       "      <td>Kaitlin</td>\n",
       "      <td>Shaffer</td>\n",
       "      <td>7</td>\n",
       "      <td>Dunns Corners Elementary School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1067</td>\n",
       "      <td>Whitney</td>\n",
       "      <td>Chapman</td>\n",
       "      <td>6</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1068</td>\n",
       "      <td>Shaun</td>\n",
       "      <td>Mejia</td>\n",
       "      <td>1</td>\n",
       "      <td>Dunns Corners Elementary School</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1069</td>\n",
       "      <td>Dean</td>\n",
       "      <td>Michael</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunny Elementary School</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    staff_id staff_first staff_last  grade_level  \\\n",
       "0       1000       Cathy  Dominguez            4   \n",
       "1       1001      Olivia       Holt            4   \n",
       "2       1002        Marc   Mcintosh            4   \n",
       "3       1003       Ricky      Mcgee            2   \n",
       "4       1004       Gavin   Holloway            1   \n",
       "..       ...         ...        ...          ...   \n",
       "65      1065      Sheena    Clayton            8   \n",
       "66      1066     Kaitlin    Shaffer            7   \n",
       "67      1067     Whitney    Chapman            6   \n",
       "68      1068       Shaun      Mejia            1   \n",
       "69      1069        Dean    Michael            1   \n",
       "\n",
       "                        school_name  \n",
       "0              Bene Gesserit School  \n",
       "1           Sunny Elementary School  \n",
       "2     Cherry Tree Elementary School  \n",
       "3        Mulberry Elementary School  \n",
       "4     Cherry Tree Elementary School  \n",
       "..                              ...  \n",
       "65       Mulberry Elementary School  \n",
       "66  Dunns Corners Elementary School  \n",
       "67             Bene Gesserit School  \n",
       "68  Dunns Corners Elementary School  \n",
       "69          Sunny Elementary School  \n",
       "\n",
       "[70 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_staff(num):\n",
    "    '''Make list of fake staff'''\n",
    "    school_list = school_names\n",
    "    grade_levels = list(range(9))\n",
    "    \n",
    "    #assign roles to staff members for permissions access in app\n",
    "    role = ['teacher','principal','admin']\n",
    "    #staff ids\n",
    "    fake_staff = [{'staff_id': x+1000,\n",
    "        'staff_first':(fake.unique.first_name()),\n",
    "        'staff_last':(fake.unique.last_name()),\n",
    "        'grade_level':np.random.choice(grade_levels),\n",
    "        'school_name': np.random.choice(school_list)\n",
    "    } for x in range(num)]\n",
    "\n",
    "    return fake_staff\n",
    "staff_df = pd.DataFrame(make_staff(70))\n",
    "\n",
    "staff_id_list = [i for i in staff_df.staff_id]\n",
    "staff_id_list\n",
    "\n",
    "year_one_cohorts = list(range(9))\n",
    "\n",
    "staff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "022b2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an association table of class_ids and teacher_ids\n",
    "school_update_2\n",
    "\n",
    "new_df = school_update_2.merge(staff_df, how='inner', on=['school_name','grade_level'])\n",
    "\n",
    "teacher_class_table = new_df[['class_id','staff_id']]\n",
    "teacher_class_table.to_csv('teacher_class_association.csv')\n",
    "# teacher_class_table\n",
    "\n",
    "# school_data = school_data.rename(columns={0:'year', 1:'school',2:'principal_id',3:'grade_level',4:'teacher_id',5:'cohort_id'})\n",
    "# school_data\n",
    "# school_update = school_data.drop(school_data[(school_data['school']=='Brown Bear Middle School') & (\n",
    "#     school_data['grade_level']<=5)].index)\n",
    "\n",
    "# school_update_2 = school_data.drop(school_data[(school_data['school']!='Brown Bear Middle School') & (\n",
    "#     school_data['grade_level']>=6)].index) \n",
    "# school_update_2.head()\n",
    "\n",
    "# school_update_2.to_csv('school_update.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "457b060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data(70, 6)\n"
     ]
    }
   ],
   "source": [
    "def make_emails(name_tuples):\n",
    "    '''Create email with first initial last name'''\n",
    "    e_list=[]\n",
    "    for name in name_tuples:\n",
    "        first_initial = name[0][0]\n",
    "        last_name = name[1]\n",
    "        email = (f'{first_initial}{last_name}@riversschooldistrict.org').lower()\n",
    "        e_list.append(email)\n",
    "    return e_list\n",
    "\n",
    "\n",
    "name_tuples = list(zip(staff_df.staff_first, staff_df.staff_last))\n",
    "\n",
    "staff_emails = make_emails(name_tuples)\n",
    "\n",
    "staff_df['email'] = staff_emails\n",
    "\n",
    "print(\"Shape of data{}\".format(staff_df.shape))\n",
    "staff_df.to_csv('staff_table.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa0be4",
   "metadata": {},
   "source": [
    "### Students <a id=\"v2_2_2\"></a>\n",
    "\n",
    "Fake students, ids, scores and classrooms assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02f81bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_names = []\n",
    "for i in range(850):\n",
    "    name = f'{fake.first_name()} {fake.last_name()}'\n",
    "    student_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4b82eefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>student_name</th>\n",
       "      <th>school_1</th>\n",
       "      <th>school_2</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>Sean Simon</td>\n",
       "      <td>State Street Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>Robert Gomez</td>\n",
       "      <td>State Street Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>Natasha Foster</td>\n",
       "      <td>State Street Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>Lisa Kline</td>\n",
       "      <td>Cherry Tree Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Daniel Robinson</td>\n",
       "      <td>Mulberry Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>10845</td>\n",
       "      <td>Bradley Allen</td>\n",
       "      <td>Sunny Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>10846</td>\n",
       "      <td>Jacqueline Tucker</td>\n",
       "      <td>State Street Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>10847</td>\n",
       "      <td>Joseph Gonzalez</td>\n",
       "      <td>State Street Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>10848</td>\n",
       "      <td>Melissa Hahn</td>\n",
       "      <td>Dunns Corners Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>10849</td>\n",
       "      <td>Mandy Morgan</td>\n",
       "      <td>Cherry Tree Elementary School</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id       student_name                         school_1  \\\n",
       "0         10000         Sean Simon   State Street Elementary School   \n",
       "1         10001       Robert Gomez   State Street Elementary School   \n",
       "2         10002     Natasha Foster   State Street Elementary School   \n",
       "3         10003         Lisa Kline    Cherry Tree Elementary School   \n",
       "4         10004    Daniel Robinson       Mulberry Elementary School   \n",
       "..          ...                ...                              ...   \n",
       "845       10845      Bradley Allen          Sunny Elementary School   \n",
       "846       10846  Jacqueline Tucker   State Street Elementary School   \n",
       "847       10847    Joseph Gonzalez   State Street Elementary School   \n",
       "848       10848       Melissa Hahn  Dunns Corners Elementary School   \n",
       "849       10849       Mandy Morgan    Cherry Tree Elementary School   \n",
       "\n",
       "                     school_2  cohort  \n",
       "0    Brown Bear Middle School       7  \n",
       "1    Brown Bear Middle School      10  \n",
       "2    Brown Bear Middle School       5  \n",
       "3    Brown Bear Middle School       6  \n",
       "4    Brown Bear Middle School       4  \n",
       "..                        ...     ...  \n",
       "845  Brown Bear Middle School       5  \n",
       "846  Brown Bear Middle School       5  \n",
       "847  Brown Bear Middle School      10  \n",
       "848  Brown Bear Middle School       7  \n",
       "849  Brown Bear Middle School       4  \n",
       "\n",
       "[850 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elementary_schools = school_names[1:]\n",
    "middle_schools = [school_names[0], school_names[-1]] \n",
    "all_cohorts = list(range(12))\n",
    "\n",
    "#creating a dict of fake students. Each will be associated with a cohort and school(s?). Anyone grades 6-8 should be in one of two schools.\n",
    "def make_students(num):\n",
    "    '''Make list of fake students'''\n",
    "    school_list = school_names\n",
    "    fake_students = [{'student_id': x+10000,\n",
    "        'student_name':(student_names[x]),\n",
    "        'school_1':np.random.choice(elementary_schools, p=[0.2,0.1,0.1,0.1,0.3,0.2]),\n",
    "        'school_2':'Brown Bear Middle School',\n",
    "        'cohort': np.random.choice(all_cohorts)\n",
    "    } for x in range(num)]\n",
    "    \n",
    "    return fake_students\n",
    "\n",
    "students_df = pd.DataFrame(make_students(850))\n",
    "\n",
    "students_cross = pd.crosstab(students_df.school_1, students_df.cohort)\n",
    "students_cross\n",
    "#ok, so we have cohorts and schools in here. to make a class roster, we need to combine this table with the classes/schools table\n",
    "\n",
    "students_df.iloc[3:6,0:2] #3 rows, 2 columns\n",
    "\n",
    "#THIS IS THE SYNTAX FOR COLUMN VALUES -- I need to make a cheat sheet/map for Pandas\n",
    "# cohorts_first_six = school_update_2.loc[(school_update_2['cohort_id'] <= 5)]\n",
    "students_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7a0e319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>principal_id</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>cohort_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>1066</td>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>1066</td>\n",
       "      <td>1</td>\n",
       "      <td>1068</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>1066</td>\n",
       "      <td>2</td>\n",
       "      <td>1067</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>1066</td>\n",
       "      <td>3</td>\n",
       "      <td>1064</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>Brown Bear Middle School</td>\n",
       "      <td>1066</td>\n",
       "      <td>4</td>\n",
       "      <td>1063</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>1007</td>\n",
       "      <td>4</td>\n",
       "      <td>1019</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>1007</td>\n",
       "      <td>5</td>\n",
       "      <td>1018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>1007</td>\n",
       "      <td>6</td>\n",
       "      <td>1051</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>1007</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>1007</td>\n",
       "      <td>8</td>\n",
       "      <td>1049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school              principal_id  grade_level  teacher_id  cohort_id  \\\n",
       "0    2021  Brown Bear Middle School         1066           0       1069   \n",
       "1    2021  Brown Bear Middle School         1066           1       1068   \n",
       "2    2021  Brown Bear Middle School         1066           2       1067   \n",
       "3    2021  Brown Bear Middle School         1066           3       1064   \n",
       "4    2021  Brown Bear Middle School         1066           4       1063   \n",
       "..    ...                       ...          ...         ...        ...   \n",
       "58   2021      Bene Gesserit School         1007           4       1019   \n",
       "59   2021      Bene Gesserit School         1007           5       1018   \n",
       "60   2021      Bene Gesserit School         1007           6       1051   \n",
       "61   2021      Bene Gesserit School         1007           7       1050   \n",
       "62   2021      Bene Gesserit School         1007           8       1049   \n",
       "\n",
       "    cohort_id  \n",
       "0           8  \n",
       "1           7  \n",
       "2           6  \n",
       "3           5  \n",
       "4           4  \n",
       "..        ...  \n",
       "58          4  \n",
       "59          3  \n",
       "60          2  \n",
       "61          1  \n",
       "62          0  \n",
       "\n",
       "[63 rows x 6 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join students_df with schools_df \n",
    "#schools_df currently only has cohorts 0-8 should make function to create classrosters\n",
    "\n",
    "# def create_rosters(df_1,df_2):\n",
    "#     # if df_2.cohort <= 5\n",
    "\n",
    "# #also need to add a function for adding school years and moving up grades. Might start there?\n",
    "\n",
    "# def add_years():\n",
    "schools_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c9092",
   "metadata": {},
   "source": [
    "#### Student Cohorts\n",
    "\n",
    "One of the biggest issues in my work that inspired me to take this course was that all of these specialized tools that we were using/creating/considering all lacked the ability to look at student performance year over year. Initially, I thought the solution might be to create cohorts almost like identifying students by their graduation year, where the cohort would be associated with a different grade each year. Ultimately, I found this was like an association table with more steps. It may be useful in some contexts, but I ended up finding it over complicated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d192a9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'cohort': [10000,\n",
       "   10001,\n",
       "   10002,\n",
       "   10003,\n",
       "   10004,\n",
       "   10005,\n",
       "   10006,\n",
       "   10007,\n",
       "   10008,\n",
       "   10009,\n",
       "   10010,\n",
       "   10011,\n",
       "   10012,\n",
       "   10013,\n",
       "   10014,\n",
       "   10015,\n",
       "   10016,\n",
       "   10017,\n",
       "   10018,\n",
       "   10019,\n",
       "   10020,\n",
       "   10021,\n",
       "   10022,\n",
       "   10023,\n",
       "   10024,\n",
       "   10025,\n",
       "   10026,\n",
       "   10027,\n",
       "   10028,\n",
       "   10029,\n",
       "   10030,\n",
       "   10031,\n",
       "   10032,\n",
       "   10033,\n",
       "   10034,\n",
       "   10035,\n",
       "   10036,\n",
       "   10037,\n",
       "   10038,\n",
       "   10039,\n",
       "   10040,\n",
       "   10041,\n",
       "   10042,\n",
       "   10043,\n",
       "   10044,\n",
       "   10045,\n",
       "   10046,\n",
       "   10047,\n",
       "   10048,\n",
       "   10049,\n",
       "   10050,\n",
       "   10051,\n",
       "   10052,\n",
       "   10053,\n",
       "   10054,\n",
       "   10055,\n",
       "   10056,\n",
       "   10057,\n",
       "   10058,\n",
       "   10059,\n",
       "   10060,\n",
       "   10061,\n",
       "   10062,\n",
       "   10063,\n",
       "   10064,\n",
       "   10065]},\n",
       " 1: {'cohort': [10066,\n",
       "   10067,\n",
       "   10068,\n",
       "   10069,\n",
       "   10070,\n",
       "   10071,\n",
       "   10072,\n",
       "   10073,\n",
       "   10074,\n",
       "   10075,\n",
       "   10076,\n",
       "   10077,\n",
       "   10078,\n",
       "   10079,\n",
       "   10080,\n",
       "   10081,\n",
       "   10082,\n",
       "   10083,\n",
       "   10084,\n",
       "   10085,\n",
       "   10086,\n",
       "   10087,\n",
       "   10088,\n",
       "   10089,\n",
       "   10090,\n",
       "   10091,\n",
       "   10092,\n",
       "   10093,\n",
       "   10094,\n",
       "   10095,\n",
       "   10096,\n",
       "   10097,\n",
       "   10098,\n",
       "   10099,\n",
       "   10100,\n",
       "   10101,\n",
       "   10102,\n",
       "   10103,\n",
       "   10104,\n",
       "   10105,\n",
       "   10106,\n",
       "   10107,\n",
       "   10108,\n",
       "   10109,\n",
       "   10110,\n",
       "   10111,\n",
       "   10112,\n",
       "   10113,\n",
       "   10114,\n",
       "   10115,\n",
       "   10116,\n",
       "   10117,\n",
       "   10118,\n",
       "   10119,\n",
       "   10120,\n",
       "   10121,\n",
       "   10122,\n",
       "   10123,\n",
       "   10124,\n",
       "   10125,\n",
       "   10126,\n",
       "   10127,\n",
       "   10128,\n",
       "   10129,\n",
       "   10130]},\n",
       " 2: {'cohort': [10131,\n",
       "   10132,\n",
       "   10133,\n",
       "   10134,\n",
       "   10135,\n",
       "   10136,\n",
       "   10137,\n",
       "   10138,\n",
       "   10139,\n",
       "   10140,\n",
       "   10141,\n",
       "   10142,\n",
       "   10143,\n",
       "   10144,\n",
       "   10145,\n",
       "   10146,\n",
       "   10147,\n",
       "   10148,\n",
       "   10149,\n",
       "   10150,\n",
       "   10151,\n",
       "   10152,\n",
       "   10153,\n",
       "   10154,\n",
       "   10155,\n",
       "   10156,\n",
       "   10157,\n",
       "   10158,\n",
       "   10159,\n",
       "   10160,\n",
       "   10161,\n",
       "   10162,\n",
       "   10163,\n",
       "   10164,\n",
       "   10165,\n",
       "   10166,\n",
       "   10167,\n",
       "   10168,\n",
       "   10169,\n",
       "   10170,\n",
       "   10171,\n",
       "   10172,\n",
       "   10173,\n",
       "   10174,\n",
       "   10175,\n",
       "   10176,\n",
       "   10177,\n",
       "   10178,\n",
       "   10179,\n",
       "   10180,\n",
       "   10181,\n",
       "   10182,\n",
       "   10183,\n",
       "   10184,\n",
       "   10185,\n",
       "   10186,\n",
       "   10187,\n",
       "   10188,\n",
       "   10189,\n",
       "   10190,\n",
       "   10191,\n",
       "   10192,\n",
       "   10193,\n",
       "   10194,\n",
       "   10195,\n",
       "   10196,\n",
       "   10197,\n",
       "   10198,\n",
       "   10199,\n",
       "   10200,\n",
       "   10201,\n",
       "   10202,\n",
       "   10203,\n",
       "   10204,\n",
       "   10205,\n",
       "   10206,\n",
       "   10207,\n",
       "   10208]},\n",
       " 3: {'cohort': [10209,\n",
       "   10210,\n",
       "   10211,\n",
       "   10212,\n",
       "   10213,\n",
       "   10214,\n",
       "   10215,\n",
       "   10216,\n",
       "   10217,\n",
       "   10218,\n",
       "   10219,\n",
       "   10220,\n",
       "   10221,\n",
       "   10222,\n",
       "   10223,\n",
       "   10224,\n",
       "   10225,\n",
       "   10226,\n",
       "   10227,\n",
       "   10228,\n",
       "   10229,\n",
       "   10230,\n",
       "   10231,\n",
       "   10232,\n",
       "   10233,\n",
       "   10234,\n",
       "   10235,\n",
       "   10236,\n",
       "   10237,\n",
       "   10238,\n",
       "   10239,\n",
       "   10240,\n",
       "   10241,\n",
       "   10242,\n",
       "   10243,\n",
       "   10244,\n",
       "   10245,\n",
       "   10246,\n",
       "   10247,\n",
       "   10248,\n",
       "   10249,\n",
       "   10250,\n",
       "   10251,\n",
       "   10252,\n",
       "   10253,\n",
       "   10254,\n",
       "   10255,\n",
       "   10256,\n",
       "   10257,\n",
       "   10258,\n",
       "   10259,\n",
       "   10260,\n",
       "   10261,\n",
       "   10262,\n",
       "   10263,\n",
       "   10264,\n",
       "   10265,\n",
       "   10266,\n",
       "   10267,\n",
       "   10268,\n",
       "   10269,\n",
       "   10270,\n",
       "   10271,\n",
       "   10272]},\n",
       " 4: {'cohort': [10273,\n",
       "   10274,\n",
       "   10275,\n",
       "   10276,\n",
       "   10277,\n",
       "   10278,\n",
       "   10279,\n",
       "   10280,\n",
       "   10281,\n",
       "   10282,\n",
       "   10283,\n",
       "   10284,\n",
       "   10285,\n",
       "   10286,\n",
       "   10287,\n",
       "   10288,\n",
       "   10289,\n",
       "   10290,\n",
       "   10291,\n",
       "   10292,\n",
       "   10293,\n",
       "   10294,\n",
       "   10295,\n",
       "   10296,\n",
       "   10297,\n",
       "   10298,\n",
       "   10299,\n",
       "   10300,\n",
       "   10301,\n",
       "   10302,\n",
       "   10303,\n",
       "   10304,\n",
       "   10305,\n",
       "   10306,\n",
       "   10307,\n",
       "   10308,\n",
       "   10309,\n",
       "   10310,\n",
       "   10311,\n",
       "   10312,\n",
       "   10313,\n",
       "   10314,\n",
       "   10315,\n",
       "   10316,\n",
       "   10317,\n",
       "   10318,\n",
       "   10319,\n",
       "   10320,\n",
       "   10321,\n",
       "   10322,\n",
       "   10323,\n",
       "   10324,\n",
       "   10325,\n",
       "   10326,\n",
       "   10327,\n",
       "   10328,\n",
       "   10329,\n",
       "   10330,\n",
       "   10331,\n",
       "   10332,\n",
       "   10333,\n",
       "   10334,\n",
       "   10335,\n",
       "   10336,\n",
       "   10337,\n",
       "   10338,\n",
       "   10339,\n",
       "   10340,\n",
       "   10341,\n",
       "   10342,\n",
       "   10343,\n",
       "   10344,\n",
       "   10345,\n",
       "   10346,\n",
       "   10347,\n",
       "   10348]},\n",
       " 5: {'cohort': [10349,\n",
       "   10350,\n",
       "   10351,\n",
       "   10352,\n",
       "   10353,\n",
       "   10354,\n",
       "   10355,\n",
       "   10356,\n",
       "   10357,\n",
       "   10358,\n",
       "   10359,\n",
       "   10360,\n",
       "   10361,\n",
       "   10362,\n",
       "   10363,\n",
       "   10364,\n",
       "   10365,\n",
       "   10366,\n",
       "   10367,\n",
       "   10368,\n",
       "   10369,\n",
       "   10370,\n",
       "   10371,\n",
       "   10372,\n",
       "   10373,\n",
       "   10374,\n",
       "   10375,\n",
       "   10376,\n",
       "   10377,\n",
       "   10378,\n",
       "   10379,\n",
       "   10380,\n",
       "   10381,\n",
       "   10382,\n",
       "   10383,\n",
       "   10384,\n",
       "   10385,\n",
       "   10386,\n",
       "   10387,\n",
       "   10388,\n",
       "   10389,\n",
       "   10390,\n",
       "   10391,\n",
       "   10392,\n",
       "   10393,\n",
       "   10394,\n",
       "   10395,\n",
       "   10396,\n",
       "   10397,\n",
       "   10398,\n",
       "   10399,\n",
       "   10400,\n",
       "   10401,\n",
       "   10402,\n",
       "   10403,\n",
       "   10404,\n",
       "   10405,\n",
       "   10406,\n",
       "   10407,\n",
       "   10408,\n",
       "   10409,\n",
       "   10410,\n",
       "   10411,\n",
       "   10412,\n",
       "   10413,\n",
       "   10414]},\n",
       " 6: {'cohort': [10415,\n",
       "   10416,\n",
       "   10417,\n",
       "   10418,\n",
       "   10419,\n",
       "   10420,\n",
       "   10421,\n",
       "   10422,\n",
       "   10423,\n",
       "   10424,\n",
       "   10425,\n",
       "   10426,\n",
       "   10427,\n",
       "   10428,\n",
       "   10429,\n",
       "   10430,\n",
       "   10431,\n",
       "   10432,\n",
       "   10433,\n",
       "   10434,\n",
       "   10435,\n",
       "   10436,\n",
       "   10437,\n",
       "   10438,\n",
       "   10439,\n",
       "   10440,\n",
       "   10441,\n",
       "   10442,\n",
       "   10443,\n",
       "   10444,\n",
       "   10445,\n",
       "   10446,\n",
       "   10447,\n",
       "   10448,\n",
       "   10449,\n",
       "   10450,\n",
       "   10451,\n",
       "   10452,\n",
       "   10453,\n",
       "   10454,\n",
       "   10455,\n",
       "   10456,\n",
       "   10457,\n",
       "   10458,\n",
       "   10459,\n",
       "   10460,\n",
       "   10461,\n",
       "   10462,\n",
       "   10463,\n",
       "   10464,\n",
       "   10465,\n",
       "   10466,\n",
       "   10467,\n",
       "   10468,\n",
       "   10469,\n",
       "   10470,\n",
       "   10471,\n",
       "   10472,\n",
       "   10473,\n",
       "   10474,\n",
       "   10475,\n",
       "   10476]},\n",
       " 7: {'cohort': [10477,\n",
       "   10478,\n",
       "   10479,\n",
       "   10480,\n",
       "   10481,\n",
       "   10482,\n",
       "   10483,\n",
       "   10484,\n",
       "   10485,\n",
       "   10486,\n",
       "   10487,\n",
       "   10488,\n",
       "   10489,\n",
       "   10490,\n",
       "   10491,\n",
       "   10492,\n",
       "   10493,\n",
       "   10494,\n",
       "   10495,\n",
       "   10496,\n",
       "   10497,\n",
       "   10498,\n",
       "   10499,\n",
       "   10500,\n",
       "   10501,\n",
       "   10502,\n",
       "   10503,\n",
       "   10504,\n",
       "   10505,\n",
       "   10506,\n",
       "   10507,\n",
       "   10508,\n",
       "   10509,\n",
       "   10510,\n",
       "   10511,\n",
       "   10512,\n",
       "   10513,\n",
       "   10514,\n",
       "   10515,\n",
       "   10516,\n",
       "   10517,\n",
       "   10518,\n",
       "   10519,\n",
       "   10520,\n",
       "   10521,\n",
       "   10522,\n",
       "   10523,\n",
       "   10524,\n",
       "   10525,\n",
       "   10526,\n",
       "   10527,\n",
       "   10528,\n",
       "   10529,\n",
       "   10530,\n",
       "   10531,\n",
       "   10532,\n",
       "   10533,\n",
       "   10534,\n",
       "   10535,\n",
       "   10536,\n",
       "   10537,\n",
       "   10538,\n",
       "   10539,\n",
       "   10540,\n",
       "   10541,\n",
       "   10542,\n",
       "   10543,\n",
       "   10544,\n",
       "   10545,\n",
       "   10546]},\n",
       " 8: {'cohort': [10547,\n",
       "   10548,\n",
       "   10549,\n",
       "   10550,\n",
       "   10551,\n",
       "   10552,\n",
       "   10553,\n",
       "   10554,\n",
       "   10555,\n",
       "   10556,\n",
       "   10557,\n",
       "   10558,\n",
       "   10559,\n",
       "   10560,\n",
       "   10561,\n",
       "   10562,\n",
       "   10563,\n",
       "   10564,\n",
       "   10565,\n",
       "   10566,\n",
       "   10567,\n",
       "   10568,\n",
       "   10569,\n",
       "   10570,\n",
       "   10571,\n",
       "   10572,\n",
       "   10573,\n",
       "   10574,\n",
       "   10575,\n",
       "   10576,\n",
       "   10577,\n",
       "   10578,\n",
       "   10579,\n",
       "   10580,\n",
       "   10581,\n",
       "   10582,\n",
       "   10583,\n",
       "   10584,\n",
       "   10585,\n",
       "   10586,\n",
       "   10587,\n",
       "   10588,\n",
       "   10589,\n",
       "   10590,\n",
       "   10591,\n",
       "   10592,\n",
       "   10593,\n",
       "   10594,\n",
       "   10595,\n",
       "   10596,\n",
       "   10597,\n",
       "   10598,\n",
       "   10599,\n",
       "   10600,\n",
       "   10601,\n",
       "   10602,\n",
       "   10603,\n",
       "   10604,\n",
       "   10605,\n",
       "   10606,\n",
       "   10607,\n",
       "   10608,\n",
       "   10609,\n",
       "   10610,\n",
       "   10611,\n",
       "   10612,\n",
       "   10613,\n",
       "   10614,\n",
       "   10615,\n",
       "   10616,\n",
       "   10617,\n",
       "   10618,\n",
       "   10619,\n",
       "   10620]},\n",
       " 9: {'cohort': [10621,\n",
       "   10622,\n",
       "   10623,\n",
       "   10624,\n",
       "   10625,\n",
       "   10626,\n",
       "   10627,\n",
       "   10628,\n",
       "   10629,\n",
       "   10630,\n",
       "   10631,\n",
       "   10632,\n",
       "   10633,\n",
       "   10634,\n",
       "   10635,\n",
       "   10636,\n",
       "   10637,\n",
       "   10638,\n",
       "   10639,\n",
       "   10640,\n",
       "   10641,\n",
       "   10642,\n",
       "   10643,\n",
       "   10644,\n",
       "   10645,\n",
       "   10646,\n",
       "   10647,\n",
       "   10648,\n",
       "   10649,\n",
       "   10650,\n",
       "   10651,\n",
       "   10652,\n",
       "   10653,\n",
       "   10654,\n",
       "   10655,\n",
       "   10656,\n",
       "   10657,\n",
       "   10658,\n",
       "   10659,\n",
       "   10660,\n",
       "   10661,\n",
       "   10662,\n",
       "   10663,\n",
       "   10664,\n",
       "   10665,\n",
       "   10666,\n",
       "   10667,\n",
       "   10668,\n",
       "   10669,\n",
       "   10670,\n",
       "   10671,\n",
       "   10672,\n",
       "   10673,\n",
       "   10674,\n",
       "   10675,\n",
       "   10676,\n",
       "   10677,\n",
       "   10678,\n",
       "   10679,\n",
       "   10680,\n",
       "   10681,\n",
       "   10682,\n",
       "   10683,\n",
       "   10684,\n",
       "   10685,\n",
       "   10686,\n",
       "   10687,\n",
       "   10688,\n",
       "   10689,\n",
       "   10690,\n",
       "   10691,\n",
       "   10692,\n",
       "   10693,\n",
       "   10694]},\n",
       " 10: {'cohort': [10695,\n",
       "   10696,\n",
       "   10697,\n",
       "   10698,\n",
       "   10699,\n",
       "   10700,\n",
       "   10701,\n",
       "   10702,\n",
       "   10703,\n",
       "   10704,\n",
       "   10705,\n",
       "   10706,\n",
       "   10707,\n",
       "   10708,\n",
       "   10709,\n",
       "   10710,\n",
       "   10711,\n",
       "   10712,\n",
       "   10713,\n",
       "   10714,\n",
       "   10715,\n",
       "   10716,\n",
       "   10717,\n",
       "   10718,\n",
       "   10719,\n",
       "   10720,\n",
       "   10721,\n",
       "   10722,\n",
       "   10723,\n",
       "   10724,\n",
       "   10725,\n",
       "   10726,\n",
       "   10727,\n",
       "   10728,\n",
       "   10729,\n",
       "   10730,\n",
       "   10731,\n",
       "   10732,\n",
       "   10733,\n",
       "   10734,\n",
       "   10735,\n",
       "   10736,\n",
       "   10737,\n",
       "   10738,\n",
       "   10739,\n",
       "   10740,\n",
       "   10741,\n",
       "   10742,\n",
       "   10743,\n",
       "   10744,\n",
       "   10745,\n",
       "   10746,\n",
       "   10747,\n",
       "   10748,\n",
       "   10749,\n",
       "   10750,\n",
       "   10751,\n",
       "   10752,\n",
       "   10753,\n",
       "   10754,\n",
       "   10755]},\n",
       " 11: {'cohort': [10756,\n",
       "   10757,\n",
       "   10758,\n",
       "   10759,\n",
       "   10760,\n",
       "   10761,\n",
       "   10762,\n",
       "   10763,\n",
       "   10764,\n",
       "   10765,\n",
       "   10766,\n",
       "   10767,\n",
       "   10768,\n",
       "   10769,\n",
       "   10770,\n",
       "   10771,\n",
       "   10772,\n",
       "   10773,\n",
       "   10774,\n",
       "   10775,\n",
       "   10776,\n",
       "   10777,\n",
       "   10778,\n",
       "   10779,\n",
       "   10780,\n",
       "   10781,\n",
       "   10782,\n",
       "   10783,\n",
       "   10784,\n",
       "   10785,\n",
       "   10786,\n",
       "   10787,\n",
       "   10788,\n",
       "   10789,\n",
       "   10790,\n",
       "   10791,\n",
       "   10792,\n",
       "   10793,\n",
       "   10794,\n",
       "   10795,\n",
       "   10796,\n",
       "   10797,\n",
       "   10798,\n",
       "   10799,\n",
       "   10800,\n",
       "   10801,\n",
       "   10802,\n",
       "   10803,\n",
       "   10804,\n",
       "   10805,\n",
       "   10806,\n",
       "   10807,\n",
       "   10808,\n",
       "   10809,\n",
       "   10810,\n",
       "   10811,\n",
       "   10812,\n",
       "   10813,\n",
       "   10814,\n",
       "   10815,\n",
       "   10816,\n",
       "   10817,\n",
       "   10818,\n",
       "   10819,\n",
       "   10820,\n",
       "   10821]}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "\n",
    "# total_classes = schools_df['class_id'].sum() #168\n",
    "# total_students = student_df['student_id'].count() #850\n",
    "# #800 students in list, between 6 & 12 kids per class,42 classes per year \n",
    "\n",
    "#create student cohorts >> cohorts are all students in a grade level in a year\n",
    "#in year 1, there will be a cohort for 0-5 spread across 6 schools = 6, plus 6-8 =9,  Then three more cohorts will enter for a total of 12\n",
    "850/12 #70\n",
    "\n",
    "student_id_list = students_df['student_id'].sort_values()\n",
    "student_id_list\n",
    "\n",
    "# #create cohorts of around 70\n",
    "\n",
    "cohort_size_list = [np.random.randint(60,80) for i in range(12)]\n",
    "\n",
    "np.sum(cohort_size_list) #should be less than 850\n",
    "cohort_size_list\n",
    "\n",
    "def group_cohorts(input, length_to_split):\n",
    "    '''Split list of student ids into cohorts of varying sizes.'''\n",
    "    \n",
    "    inputt = iter(input)\n",
    "    output = [list(islice(inputt, elem))\n",
    "              for elem in length_to_split]\n",
    "    # Printing Output \n",
    "    return output\n",
    "\n",
    "cohort_groups = group_cohorts(student_id_list, cohort_size_list)\n",
    "cohort_size_list\n",
    "\n",
    "def enum():\n",
    "    dict = {}\n",
    "    for count, value in enumerate(cohort_groups):\n",
    "        dict[count]={\n",
    "            'cohort':value\n",
    "        }\n",
    "    return dict\n",
    "\n",
    "cohort_nums = enum()\n",
    "cohort_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9bf364cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2021, 2022, 2023, 2024]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assign each cohort to a grade level\n",
    "in the first year, the first 9 cohorts are assigned to a grade\n",
    "in the next year, the cohorts move up a grade and a new cohort enters prek\n",
    "2021 - cohorts 0-8 | 2022 - cohorts 9,0-7, 2023 - cohorts 9,10,0-6, 2024 = cohorts 9-11,0-5\n",
    "'''\n",
    "cohorts_df = pd.DataFrame(cohort_groups, dtype='Int64')\n",
    "\n",
    "\n",
    "cohorts_dict =cohorts_df.to_dict('index')\n",
    "coh_nums = [i for i in cohorts_dict.keys()] #list\n",
    "\n",
    "\n",
    "# cohorts            0   1   2   3   4   5   6   7   8 || 9   0   1   2   3   4   5   6   7 || 9   10  0   1   2   3   4   5  6 ||9  10  11   0   1   2   3   4  5 |\n",
    "# grade_level        0   1   2   3   4   5   6   7   8 || 0   1   2   3   4   5   6   7   8 || 0   1   2   3   4   5   6   7  8 ||0   1   2   3   4   5   6   7  8 |   \n",
    "# year               |--------------2021---------------||--------------2022-----------------||--------------2023----------------||--------------2024---------------|\n",
    "\n",
    "# year range 4, grades range 9  \n",
    "# i = cohort[-1], cohort[0] = sum(i+1), cohort.pop(i) <pointer/node     \n",
    "#input > schools_df, elements = year, grade_level\n",
    "\n",
    "\n",
    "cohorts_df = cohorts_df.transpose()\n",
    "school_update_2\n",
    "start_year = 2021\n",
    "grades\n",
    "years\n",
    "school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9c49a1f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on int64 and object columns for key 'year'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[156], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m scores_df \u001b[38;5;241m=\u001b[39m scores_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mold_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnnamed: 9\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# new_df = pd.merge(A_df, B_df,  how='left', left_on=['A_c1','c2'], right_on = ['B_c1','c2'])\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m scores_df \u001b[38;5;241m=\u001b[39m \u001b[43mscores_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschools_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mschool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrade\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mschool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgrade_level\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m scores_df \u001b[38;5;241m=\u001b[39mscores_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschool\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrade_level\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#backing up, create all new score data for fake data set\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:10487\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10468\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10469\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10483\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10484\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10485\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10496\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10497\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:169\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[0;32m    155\u001b[0m         left_df,\n\u001b[0;32m    156\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:804\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 804\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py:1479\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1475\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1476\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1477\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1478\u001b[0m     ):\n\u001b[1;32m-> 1479\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on int64 and object columns for key 'year'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "#decided to merge fake data with old score data to simplify/keep work already done <<< Changed my mind.\n",
    "scores_df = pd.read_csv('assessment_scores.csv', dtype={\n",
    "    'year':'int64',\n",
    "    'period':'int64',\n",
    "    'grade':'int64',\n",
    "    'student_score':'float64',\n",
    "    'assessment_id':'string',\n",
    "    'student_id':'int64'\n",
    "})\n",
    "\n",
    "scores_df = scores_df.drop(columns=['old_id', 'Unnamed: 8','Unnamed: 9'])\n",
    "# new_df = pd.merge(A_df, B_df,  how='left', left_on=['A_c1','c2'], right_on = ['B_c1','c2'])\n",
    "\n",
    "scores_df = scores_df.merge(school_data, how='inner',left_on=['school','year','grade'],right_on=['school','year','grade_level'])\n",
    "scores_df =scores_df.drop(columns=['school', 'grade_level'])\n",
    "\n",
    "#backing up, create all new score data for fake data set\n",
    "scores_data_var = scores_df.groupby(['assessment_id'], as_index=False).mean(numeric_only=True).round()[['assessment_id','student_score']]\n",
    "\n",
    "score_avgs = scores_df.groupby(['assessment_id','period'], as_index=False).describe()[['assessment_id','period','student_score']]\n",
    "\n",
    "score_avgs.loc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc136f",
   "metadata": {},
   "source": [
    "## Assessment Information <a id=\"v2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb0c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>assessment_id</th>\n",
       "      <th>assessment_name</th>\n",
       "      <th>assessment_short_name</th>\n",
       "      <th>assessment_family</th>\n",
       "      <th>assessment_type</th>\n",
       "      <th>assessment_subject</th>\n",
       "      <th>content_standard</th>\n",
       "      <th>standard_id</th>\n",
       "      <th>rank_name</th>\n",
       "      <th>rank_score</th>\n",
       "      <th>period_id</th>\n",
       "      <th>grade_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AWAV</td>\n",
       "      <td>Auditory Vocabulary</td>\n",
       "      <td>AV</td>\n",
       "      <td>Aimsweb Plus</td>\n",
       "      <td>Benchmark</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>National</td>\n",
       "      <td>1</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AWAV</td>\n",
       "      <td>Auditory Vocabulary</td>\n",
       "      <td>AV</td>\n",
       "      <td>Aimsweb Plus</td>\n",
       "      <td>Benchmark</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>National</td>\n",
       "      <td>2</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AWAV</td>\n",
       "      <td>Auditory Vocabulary</td>\n",
       "      <td>AV</td>\n",
       "      <td>Aimsweb Plus</td>\n",
       "      <td>Benchmark</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>National</td>\n",
       "      <td>3</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>17.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AWAV</td>\n",
       "      <td>Auditory Vocabulary</td>\n",
       "      <td>AV</td>\n",
       "      <td>Aimsweb Plus</td>\n",
       "      <td>Benchmark</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>National</td>\n",
       "      <td>4</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>19.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AWAV</td>\n",
       "      <td>Auditory Vocabulary</td>\n",
       "      <td>AV</td>\n",
       "      <td>Aimsweb Plus</td>\n",
       "      <td>Benchmark</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>National</td>\n",
       "      <td>5</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>21.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>484</td>\n",
       "      <td>PNOAEQ</td>\n",
       "      <td>Equality</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Primary Number &amp; Operations Assessment</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Math</td>\n",
       "      <td>State</td>\n",
       "      <td>172</td>\n",
       "      <td>Tier I</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>485</td>\n",
       "      <td>PNOAEQ</td>\n",
       "      <td>Equality</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Primary Number &amp; Operations Assessment</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Math</td>\n",
       "      <td>State</td>\n",
       "      <td>343</td>\n",
       "      <td>Tier II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>PNOAEQ</td>\n",
       "      <td>Equality</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Primary Number &amp; Operations Assessment</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Math</td>\n",
       "      <td>State</td>\n",
       "      <td>344</td>\n",
       "      <td>Tier II</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>487</td>\n",
       "      <td>PNOAEQ</td>\n",
       "      <td>Equality</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Primary Number &amp; Operations Assessment</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Math</td>\n",
       "      <td>State</td>\n",
       "      <td>515</td>\n",
       "      <td>Tier III</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>488</td>\n",
       "      <td>PNOAEQ</td>\n",
       "      <td>Equality</td>\n",
       "      <td>EQ</td>\n",
       "      <td>Primary Number &amp; Operations Assessment</td>\n",
       "      <td>Diagnostic</td>\n",
       "      <td>Math</td>\n",
       "      <td>State</td>\n",
       "      <td>516</td>\n",
       "      <td>Tier III</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 assessment_id      assessment_name assessment_short_name  \\\n",
       "0             0          AWAV  Auditory Vocabulary                    AV   \n",
       "1             1          AWAV  Auditory Vocabulary                    AV   \n",
       "2             2          AWAV  Auditory Vocabulary                    AV   \n",
       "3             3          AWAV  Auditory Vocabulary                    AV   \n",
       "4             4          AWAV  Auditory Vocabulary                    AV   \n",
       "..          ...           ...                  ...                   ...   \n",
       "484         484        PNOAEQ             Equality                    EQ   \n",
       "485         485        PNOAEQ             Equality                    EQ   \n",
       "486         486        PNOAEQ             Equality                    EQ   \n",
       "487         487        PNOAEQ             Equality                    EQ   \n",
       "488         488        PNOAEQ             Equality                    EQ   \n",
       "\n",
       "                          assessment_family assessment_type  \\\n",
       "0                              Aimsweb Plus       Benchmark   \n",
       "1                              Aimsweb Plus       Benchmark   \n",
       "2                              Aimsweb Plus       Benchmark   \n",
       "3                              Aimsweb Plus       Benchmark   \n",
       "4                              Aimsweb Plus       Benchmark   \n",
       "..                                      ...             ...   \n",
       "484  Primary Number & Operations Assessment      Diagnostic   \n",
       "485  Primary Number & Operations Assessment      Diagnostic   \n",
       "486  Primary Number & Operations Assessment      Diagnostic   \n",
       "487  Primary Number & Operations Assessment      Diagnostic   \n",
       "488  Primary Number & Operations Assessment      Diagnostic   \n",
       "\n",
       "    assessment_subject content_standard  standard_id rank_name  rank_score  \\\n",
       "0             Literacy         National            1    Tier I        16.2   \n",
       "1             Literacy         National            2    Tier I        19.5   \n",
       "2             Literacy         National            3    Tier I        17.7   \n",
       "3             Literacy         National            4    Tier I        19.9   \n",
       "4             Literacy         National            5    Tier I        21.8   \n",
       "..                 ...              ...          ...       ...         ...   \n",
       "484               Math            State          172    Tier I         3.0   \n",
       "485               Math            State          343   Tier II         9.0   \n",
       "486               Math            State          344   Tier II         5.0   \n",
       "487               Math            State          515  Tier III        12.0   \n",
       "488               Math            State          516  Tier III        12.0   \n",
       "\n",
       "     period_id  grade_id  \n",
       "0            1         0  \n",
       "1            3         0  \n",
       "2            2         0  \n",
       "3            1         1  \n",
       "4            3         1  \n",
       "..         ...       ...  \n",
       "484          2         1  \n",
       "485          3         1  \n",
       "486          2         1  \n",
       "487          3         1  \n",
       "488          2         1  \n",
       "\n",
       "[489 rows x 13 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing assessment data (real assessments and standards!)\n",
    "\n",
    "assessments_df = pd.read_csv('exports/assessments.csv')\n",
    "# assessments_df\n",
    "\n",
    "# assessment_standards_df = pd.read_csv('assessment_standards.csv')\n",
    "# assessment_standards_df.head()\n",
    "\n",
    "# #changing case and names for consistency\n",
    "# assessment_standards_df=assessment_standards_df.rename(columns={\n",
    "#     'AssessmentStandardID':'standard_id', \n",
    "#     'RankName':'rank_name',\n",
    "#     'RankScore':'rank_score',\n",
    "#     'AssessmentId':'assessment_id',\n",
    "#     'PeriodId':'period_id',\n",
    "#     'GradeLevelId':'grade_id'})\n",
    "# #inplace=True doesn't work here\n",
    "\n",
    "# assessment_standards_df\n",
    "\n",
    "# assessments_df=assessments_df.rename(columns={\n",
    "#     'AssessmentId':'assessment_id',\n",
    "#     'AssessmentName':'assessment_name',\n",
    "#     'ShortAssessmentName':'assessment_short_name',\n",
    "#     'AssessmentFamily':'assessment_family',\n",
    "#     'AssessmentType':'assessment_type',\n",
    "#     'AcademicSubject':'assessment_subject',\n",
    "#     'ContentStandard':'content_standard'\n",
    "# })\n",
    "# assessments_df_copy = assessments_df\n",
    "\n",
    "# assessments_df = assessments_df.merge(assessment_standards_df, how='inner', on='assessment_id')\n",
    "\n",
    "assessments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb9875",
   "metadata": {},
   "source": [
    "#### Test Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d737b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>year</th>\n",
       "      <th>school</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>teacher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21-0-Ben</td>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>0</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21-1-Ben</td>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>1</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21-2-Ben</td>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>2</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21-3-Ben</td>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>3</td>\n",
       "      <td>2974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21-4-Ben</td>\n",
       "      <td>2021</td>\n",
       "      <td>Bene Gesserit School</td>\n",
       "      <td>4</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>24-1-Sun</td>\n",
       "      <td>2024</td>\n",
       "      <td>Sunny Elementary School</td>\n",
       "      <td>1</td>\n",
       "      <td>1774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>24-2-Sun</td>\n",
       "      <td>2024</td>\n",
       "      <td>Sunny Elementary School</td>\n",
       "      <td>2</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>24-3-Sun</td>\n",
       "      <td>2024</td>\n",
       "      <td>Sunny Elementary School</td>\n",
       "      <td>3</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>24-4-Sun</td>\n",
       "      <td>2024</td>\n",
       "      <td>Sunny Elementary School</td>\n",
       "      <td>4</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>24-5-Sun</td>\n",
       "      <td>2024</td>\n",
       "      <td>Sunny Elementary School</td>\n",
       "      <td>5</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class_id  year                   school  grade_level  teacher\n",
       "0    21-0-Ben  2021     Bene Gesserit School            0     1338\n",
       "1    21-1-Ben  2021     Bene Gesserit School            1     1056\n",
       "2    21-2-Ben  2021     Bene Gesserit School            2     2242\n",
       "3    21-3-Ben  2021     Bene Gesserit School            3     2974\n",
       "4    21-4-Ben  2021     Bene Gesserit School            4     1207\n",
       "..        ...   ...                      ...          ...      ...\n",
       "163  24-1-Sun  2024  Sunny Elementary School            1     1774\n",
       "164  24-2-Sun  2024  Sunny Elementary School            2     1413\n",
       "165  24-3-Sun  2024  Sunny Elementary School            3     1413\n",
       "166  24-4-Sun  2024  Sunny Elementary School            4     1150\n",
       "167  24-5-Sun  2024  Sunny Elementary School            5     1150\n",
       "\n",
       "[168 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classroom_df = pd.read_csv('new_class.csv')\n",
    "\n",
    "classroom_df=classroom_df.drop(columns=['Unnamed: 5','Unnamed: 6','Unnamed: 7','Unnamed: 8','Unnamed: 9'])\n",
    "classroom_df['num_students'] = np.random.ranint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e28af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2657, 2013, 2790, 2639, 1366, 2941, 2146, 1006, 2582, 2735, 2605, 2504, 1973, 1798, 1011, 1634, 2962, 1507, 1953, 2125, 1891, 1776, 1314, 2288, 1476, 2968, 2852, 2928, 2247, 2134, 1983, 1064, 1472, 1846, 2388, 1201, 2806, 1154, 1324, 1749, 1155, 2006, 2502, 1093, 2627, 1182, 2865, 1005, 1166, 1224, 1690, 1691, 2823, 2590, 1205, 2165, 2732, 1458, 1860, 2766, 1500, 2753, 2840, 2095, 2116, 2656, 2325, 2994, 2311, 1149, 2662, 1072, 1835, 1985, 2651, 1548, 1352, 1920, 2653, 1791, 1147, 1567, 2307, 2466, 2141, 1393, 2872, 1085, 1060, 2758, 1088, 2248, 1220, 2355, 2607, 1330, 1742, 1737, 2245, 2086, 1074, 1217, 2263, 1119, 1207, 2844, 1605, 2634, 1157, 1074, 2330, 2777, 1312, 1177, 2060, 2669, 2970, 2985, 1541, 1309, 1508, 1587, 1854, 1628, 2406, 1217, 1247, 1366, 2474, 2765, 1005, 1021, 1152, 1325, 2504, 1554, 1330, 1162, 2629, 2129, 2649, 2295, 2830, 1266, 1252, 2068, 2482, 2391, 2430, 2739, 2389, 2932, 2600, 1758, 2120, 1580, 1977, 1478, 2136, 1658, 2017, 1704, 1767, 1922, 1468, 1853, 2743, 1858, 2638, 2931, 2543, 2012, 1376, 2997, 1139, 1798, 1400, 2944, 1467, 2792, 2320, 2085, 1316, 2753, 1308, 1819, 1928, 2242, 1461, 1117, 1961, 1379, 2525, 2150, 2647, 2915, 1434, 2923, 2792, 2837, 2972, 1496, 2995, 2228, 1689, 1687, 2269, 1224, 1007, 2442, 1558, 1090, 2114, 1235, 2903, 2773, 1521, 2700, 1699, 1613, 1019, 2038, 2828, 1569, 1169, 1439, 1021, 1043, 2081, 2971, 1984, 2157, 1129, 2440, 1262, 2866, 2791, 2096, 2531, 2697, 1056, 2510, 1625, 1246, 1330, 1265, 2912, 1273, 1588, 1101, 1451, 1650, 1369, 2186, 2317, 2475, 1295, 2960, 2075, 2970, 2669, 2252, 1173, 1938, 2993, 2957, 1617, 1353, 2471, 1364, 2689, 1372, 2633, 1973, 2456, 1804, 2470, 2740, 2622, 1216, 1109, 2162, 1916, 2250, 2711, 2290, 2683, 1039, 1704, 1450, 2586, 1075, 2898, 1571, 1504, 1161, 2101, 2152, 2482, 1679, 2662, 1372, 2597, 1801, 2063, 2292, 1222, 2775, 2122, 1532, 1114, 2811, 2905, 1070, 1394, 1090, 1420, 1708, 2298, 1746, 2909, 2908, 1778, 2532, 2024, 2502, 2042, 2505, 1958, 2942, 2313, 2921, 2136, 1712, 1092, 2975, 1635, 1350, 2847, 2941, 1954, 1247, 1139, 1704, 1643, 1274, 1122, 1932, 1138, 1755, 1324, 2894, 1638, 1874, 1037, 2323, 1133, 1325, 2876, 2922, 2088, 2865, 1289, 2921, 2478, 1953, 2482, 2029, 2693, 2981, 1908, 1834, 1214, 2752, 1022, 1806, 2994, 2794, 2268, 1999, 2816, 2542, 1880, 1330, 2919, 1054, 2697, 1103, 1152, 2907, 1648, 2146, 2794, 1044, 2323, 2961, 1114, 2573, 1371, 2914, 2724, 2089, 1524, 2716, 2224, 1255, 2279, 2723, 1115, 1393, 1591, 1118, 2012, 2245, 1170, 2641, 1164, 1379, 2734, 1840, 2354, 1568, 2551, 2962, 2517, 1826, 2818, 2055, 1023, 2382, 2724, 2553, 2217, 1813, 1441, 1617, 2789, 2914, 1577, 1394, 1420, 1463, 2441, 1614, 2661, 2866, 1926, 1208, 2346, 2160, 2155, 1941, 1229, 2183, 1666, 2004, 1730, 1188, 1010, 1069, 1314, 1130, 2043, 1697, 1082, 2583, 1032, 2228, 1565, 1215, 2135, 1182, 2417, 2973, 2667, 2953, 2183, 2447, 2171, 2250, 2885, 2158, 1219, 2442, 1006, 1443, 1339, 2716, 1587, 2644, 1105, 1057, 2995, 2588, 2689, 2752, 1184, 2425, 1030, 2645, 2617, 2098, 2823, 2159, 2383, 2659, 1613, 2181, 2830, 1771, 1876, 2268, 2586, 2708, 2693, 2657, 1569, 2755, 1801, 1021, 1564, 1407, 1970, 2778, 1462, 1783, 1666, 1569, 2483, 1780, 2302, 2978, 2885, 2410, 2864, 2318, 1788, 1006, 1529, 2602, 2731, 2677, 1800, 1181, 2841, 1329, 2187, 1796, 2565, 2093, 2460, 1125, 2099, 2148, 2586, 2816, 2025, 1201, 2380, 2101, 1603, 2147, 2214, 2552, 1179, 2688, 1819, 1102, 1683, 2014, 1189, 2190, 2183, 2618, 2941, 1270, 1274, 2321, 1792, 1425, 2459, 1383, 1153, 1282, 2189, 2437, 2409, 1711, 2499, 2244, 1889, 2936, 2162, 2849, 1836, 2154, 2988, 2523, 2280, 2773, 1334, 2635, 1839, 1633, 2351, 2188, 2613, 1821, 1776, 1818, 1390, 1542, 2348, 2821, 1187, 2089, 2877, 1373, 2365, 2456, 1741, 1952, 1345, 2178, 2223, 1983, 2783, 1078, 1251, 2039, 2180, 1782, 1028, 1915, 1108, 1927, 1533, 2879, 1898, 1568, 1881, 1322, 1742, 1089, 1881, 1173, 1390, 1697, 1651, 1786, 2915, 1563, 2230, 2267, 2422, 2794, 2513, 2281, 1712, 1321, 1898, 1919, 2372, 1034, 2848, 2863, 2934, 2434, 2451, 2032, 2034, 2890, 1964, 1781, 1913, 2673, 2861, 2769, 1961, 1662, 2766, 2475, 2443, 1142, 1418, 2405, 2004, 1211, 1271, 1670, 2847, 1102, 2343, 2154, 2357, 1082, 2816, 2472, 1984, 1003, 2185, 2114, 1068, 1169, 2354, 1798, 1323, 1059, 1622, 1478, 1463, 1095, 2038, 2547, 1508, 1331, 1115, 2034, 2467, 1890, 2008, 1999, 2231, 2259, 1605, 2871, 2214, 2619, 1903, 2466, 2035, 1410, 1915, 2556, 1270, 2326, 2537, 2334, 2066, 1026, 1446, 1191, 2909, 2623, 1776, 2064, 1468, 1081, 2594, 1077, 1910, 2403, 2298, 1076, 2106, 1102, 2119, 1619, 1027, 1221, 1248, 1867, 1192, 2218, 1533, 1118, 2146, 1926, 2308, 2940, 1281, 1834, 2442, 2917, 1421, 1049, 2029, 1168, 2343, 2892, 2317, 2340, 2134, 1586, 1357, 2434, 2638, 1114, 1363, 2739, 1325, 1091, 2939, 2487, 1458, 1507, 2713, 2827, 1904, 1856, 2951, 1401, 2163, 1048, 1787, 1271, 1841, 1066, 1014, 2554, 1491, 1101, 1972, 1404, 2123, 1065, 1968, 1069, 1889, 1393, 2387, 1348, 1400, 2414, 1508, 2135, 2948, 1732, 1187, 1672, 1988, 1752, 1519, 1325, 2624, 2191, 1043, 1119, 1246, 2794, 1216, 2297, 1235, 1006, 2666, 2351, 2825, 2619, 1708, 2342]\n"
     ]
    }
   ],
   "source": [
    "# importing the required module\n",
    "import random\n",
    "\n",
    "# list of items\n",
    "student_id_list = list(students_df['student_id'])\n",
    "\n",
    "# # using the sample() method\n",
    "# UpdatedList = random.sample(List, 3)\n",
    "\n",
    "# # displaying random selections from \n",
    "# # the list without repetition\n",
    "# print(UpdatedList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
